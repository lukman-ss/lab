# OP-Detector
![Sample Output](image.png) 
A Kedro-based computer vision pipeline to detect One Piece anime characters using a custom dataset scraped from DuckDuckGo.

## Project Structure

```
op-detector/
â”œâ”€â”€ conf/
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ catalog.yml
â”‚   â”‚   â”œâ”€â”€ parameters.yml
â”‚   â”‚   â”œâ”€â”€ parameters_data_engineering.yml
â”‚   â”‚   â”œâ”€â”€ parameters_train.yml
â”‚   â”‚   â””â”€â”€ parameters_detect.yml
â”‚   â””â”€â”€ local/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ 01_raw/
â”‚   â”‚   â””â”€â”€ images/                 # Raw images scraped by data_engineering
â”‚   â”œâ”€â”€ 06_models/
â”‚   â”‚   â””â”€â”€ op_character_resnet.pth # Trained model checkpoint
â”‚   â””â”€â”€ detect/
â”‚       â””â”€â”€ test.jpg               # Sample image for inference
â”œâ”€â”€ src/op_detector/
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ data_engineering/
â”‚   â”‚   â”‚   â”œâ”€â”€ nodes.py
â”‚   â”‚   â”‚   â””â”€â”€ pipeline.py
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â”œâ”€â”€ nodes.py
â”‚   â”‚   â”‚   â””â”€â”€ pipeline.py
â”‚   â”‚   â””â”€â”€ detect/
â”‚   â”‚       â”œâ”€â”€ nodes.py
â”‚   â”‚       â””â”€â”€ pipeline.py
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Setup

1. **Clone the repo** and navigate in:

   ```bash
   git clone https://github.com/lukman-ss/lab.git
   cd 10-op-detector/op-detector
   ```

2. **Create and activate a virtual environment**:

   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   ```

3. **Install dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

4. **Ensure SSL certificates** (macOS only):

   ```bash
   pip install certifi
   ```

## Pipelines

### 1. Data Engineering (Scrape Images)

Pull images for each One Piece character using DuckDuckGo.

```bash
kedro run --pipeline=data_engineering
```

* Configured via `conf/base/parameters_data_engineering.yml`:

  ```yaml
  characters:
    - Monkey D. Luffy
    - Roronoa Zoro
    # ...
  max_results: 200
  raw_images_dir: "data/01_raw/images"
  ```

### 2. Train (Model Training)

Train a ResNet18 classifier on the scraped images.

```bash
kedro run --pipeline=train
```

* Configured via `conf/base/parameters_train.yml`:

  ```yaml
  train:
    raw_images_dir: "data/01_raw/images"
    model_output:   "data/06_models/op_character_resnet.pth"
    epochs:         5
  ```

### 3. Detect (Inference)

Run inference on a single image to predict the character.

```bash
kedro run --pipeline=detect --params="detect.image_path=data/detect/test.jpg"
```

* Configured via `conf/base/parameters_detect.yml`:

  ```yaml
  detect:
    image_path: "data/detect/test.jpg"
  ```

## Adding New Characters

1. Update `characters` list in `conf/base/parameters_data_engineering.yml`.
2. Re-run the data engineering pipeline:

   ```bash
   kedro run --pipeline=data_engineering
   ```
3. Re-run training to include new classes:

   ```bash
   kedro run --pipeline=train
   ```

## Notes

* **Partial prototype**: You can train and test on whatever subset of data you haveâ€”empty folders are skipped automatically.
* **Lazy imports**: DuckDuckGo scraping is only imported when running the scrape pipeline, so inference runs in isolation.

---

Happy detecting! ðŸš€
